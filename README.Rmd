---
title: "Your Guide to DataFest"
author: "Chris Nobblitt"
date: "March 28, 2017"
output: 
  html_document:
    toc: TRUE
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##### Adapted work from [tyson-ni](https://github.com/tyson-ni/DataFest-Guide) on GitHub



## **Stategies For Large Datasets in R:**

> R stores its objects in RAM...So, close Chrome!

**Limit RAM Usage** There's not a lot of it...

 * Kill programs other than R (especially Chrome)
 * Read a subset of original data
 * Remove unnecessary columns


*** 


## Download The Data

Click *Download Sample Data* and save to the *data* folder in your working directory (where your R code is)

* [Download](https://www.ookla.com/speedtest-intelligence)


_**Remember**_: Whenever you have questions about how to use code or what to put in a function, type this in console:

*`?feature-I-am-confused-about`*


***


## Importing Data


### readr

Imports and exports data *much* faster than default R.

* [manual](https://github.com/hadley/readr/blob/master/README.md)

``` {r, eval=FALSE}
# Run this if you havn't installed readr
install.packages("readr")
```

### Subset the Data!

Start with a *small* sample (e.g. 500 - 5000 observations) of the original dataset. Read increasingly more observations in as you grow comfortable AND have working code.

Readr also has a nifty **progress bar**!

``` {r, warning=FALSE}
library(readr)
tbl <- read_csv("data/android_data_sample.csv", n_max=50)
```

### Exclude unnecessary columns
If there is information not useful for anything, take it out!

``` {r}
head(tbl$test_id)
```

Hmm... we don't really need test_id for our analysis.
Remove it! (The FIRST column)

```{r}
tbl <- tbl[, -1] # Keep everything but the 1st column
names(tbl)
```

***

  
## Cleaning and Analyzing Data

You'll spend the most time cleaning data. Don't give up. Patience pays off.


### dplyr

The single most powerful library in R. Summarize, filter, remove, transform and create new data... You'll save lots of time and trouble if you use this instead of default R.

* [best intro tutorial](https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html)

* [PDF cheatsheet](https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)

* [another tutorial](http://genomicsclass.github.io/book/pages/dplyr_tutorial.html)

* [yet another tutorial](http://www.r-bloggers.com/data-manipulation-with-dplyr/)

#### Pipe Operators
*%>%* Saves a lot of memory, and is much more readable

```{r, eval=FALSE}
 dataset <- read_csv(android) %>%
          dplyr::group_by(device) %>%
          dplyr::summarise(avgSpeed = download_kbps) %>%
          dplyr::arrange(avgSpeed)
```
             
This is the same code as:

```{r, eval=FALSE}
data set <- arrange(summarise(group_by(read_csv(android), device), avgSpeed = download_kbps), avgSpeed))
```


### stringr

Great for working with strings

* [tutorial](https://cran.r-project.org/web/packages/stringr/vignettes/stringr.html)

### lubridate

* A quick way to format variables that store time and dates
* [tutorial](https://cran.r-project.org/web/packages/lubridate/vignettes/lubridate.html)

### regular expression (regex)

> Let's say you want to extract the height and width dimensions in an artworks dataset. The original variable stores the info like this mess: `19 1/8 x 66 1/2"(48.6 x 168.9cm)`

> We only care about `48.6` and `168.9`. We do this through REGEX. 

> This is the regex pattern to get `48.6` : `"\\(([:digit:]+\\.*[:digit:]*)\\s[x×]"`

> This is the regex pattern to get `168.9` : `"[x×]\\s([:digit:]+\\.*[:digit:]*)\\scm"`

* Great website to learn regex and practice live! 
* [link](http://www.regexr.com/)


***

### pandas in Python

For Python coders

* [10 minute tutorial](http://pandas.pydata.org/pandas-docs/version/0.15.2/10min.html#min)

***


### Quartz's guide to bad data

* A collection of common data recording problems and ways to fix them
* [link](https://github.com/Quartz/bad-data-guide)

***

## Visualization

Wanna win the Best Visualization prize?

### ggplot2

Best library for creating graphics in R

### Tableau

A software for creating graphics using drag and drop interface. No code necessary. Play around with this if you're stuck! Tableau Public is free.

* [download](https://public.tableau.com/s/download)
* [tutorial](http://dh101.humanities.ucla.edu/?page_id=163)
* [gallery](https://public.tableau.com/s/gallery)

### D3

Behind some of the most impressive interactive visualizations. Great for creating original graphics that perfectly matches your quirky mental model of what data looks like.

* [great series of tutorials](http://alignedleft.com/tutorials/d3/)
* [demos with code included](http://bl.ocks.org/mbostock)
* [reference manual](https://github.com/mbostock/d3/wiki/API-Reference)

***

## Machine Learning

> Everybody is talking about it. From my experience, DataFest judges want you to *explain why something is the case* rather than predict what might happen. Machine learning usually excels at prediction but not explanation. But definitely take this opportunity to practice ML.

### A curated list of resources

This person did an amazing job covering topics from classification and regression to deep learning and ensembles 

* [link](https://github.com/ujjwalkarn/Machine-Learning-Tutorials)

## Practice!
Use these datasets as practice - a truly awesome collection of many kinds of public datasets, covering weather, economics, health and many more

* [link](https://github.com/caesar0301/awesome-public-datasets)








